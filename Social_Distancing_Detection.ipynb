{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('image.jpg')\n",
    "resized = cv2.resize(img,(500,500))\n",
    "gray = cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"faces\",gray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[256 131  36  36]\n",
      " [210 149  41  41]\n",
      " [296 247  50  50]\n",
      " [384 121  46  46]\n",
      " [156 131  42  42]\n",
      " [289 134  43  43]\n",
      " [108 114  50  50]\n",
      " [174 252  49  49]\n",
      " [342  96  42  42]\n",
      " [193 100  40  40]]\n"
     ]
    }
   ],
   "source": [
    "faces = facecascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5,minSize=(20,20))\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(resized,(x,y),(x+w,y+h),(0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"faces detected\",resized)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"faces_detected.jpg\",resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret,frame = webcam.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = facecascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5,minSize=(20,20))\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        roi = frame[y:y+h,x:x+w]\n",
    "    cv2.imshow(\"Live_Faces\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('w'):\n",
    "        cv2.imwrite('my_face.jpg',roi)\n",
    "    elif cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"room.jpg\")\n",
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            #Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "#NMS - non max suppression\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x,y,w,h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "        cv2.putText(img,label,(x,y+30),font,3,color,3)\n",
    "cv2.imshow(\"ROOM_IMAGE\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"Objects_detected.jpg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,img = video.read()\n",
    "    height,width,channels = img.shape\n",
    "    #detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    #showing information on screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                #objects detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                #Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    #print indexes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "    #NMS - non max suppression\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "            cv2.putText(img,label,(x,y+30),font,3,color,3)\n",
    "    cv2.imshow(\"Live_Cam\",img)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "# Load Yolo\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "np.random.uniform(0, 255, size=(len(classes),3))\n",
    "\n",
    "#start video\n",
    "\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "#cap = cv2.VideoCapture('http://192.168.43.1:8080//video')\n",
    "\n",
    "\n",
    "def E_dist(p1, p2):\n",
    "\n",
    "    return ((p1[0] - p2[0]) ** 2 +  (p1[1] - p2[1]) ** 2) ** 0.5\n",
    "\n",
    "def isclose(p1, p2):\n",
    "\n",
    "    c_d = E_dist(p1, p2)\n",
    "\n",
    "    calib = (p1[1] + p2[1]) / 2\n",
    "\n",
    "    if 0 < c_d < 0.15 * calib:\n",
    "\n",
    "        return 1\n",
    "\n",
    "    elif 0 < c_d < 0.2 * calib:\n",
    "\n",
    "        return 2\n",
    "\n",
    "    else:\n",
    "\n",
    "        return 0\n",
    "\n",
    "    \n",
    "\n",
    "height,width=(None,None)\n",
    "\n",
    "q=0       \n",
    "\n",
    "#Start working on video or camera\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, img = cap.read()  \n",
    "\n",
    "    print(ret)\n",
    "\n",
    "    if not ret:\n",
    "\n",
    "        break\n",
    "\n",
    "    if width is None or height is None: \n",
    "\n",
    "        height,width=img.shape[:2]\n",
    "\n",
    "        q=width\n",
    "\n",
    "    #height, width, channels = img.shape\n",
    "\n",
    "    img =img[0:height, 0:q]\n",
    "\n",
    "    height,width=img.shape[:2]\n",
    "\n",
    "    # Detecting objects 0.00392\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img,0.00392, (416, 416), (0,0,0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    end=time.time()\n",
    "\n",
    "     # Showing informations on the screen\n",
    "\n",
    "    class_ids = []\n",
    "\n",
    "    confidences = []\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "\n",
    "        for detection in out:\n",
    "\n",
    "            scores = detection[5:]\n",
    "\n",
    "            class_id = np.argmax(scores)\n",
    "\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            #0.5 is the threshold for confidence\n",
    "\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                # Object detected\n",
    "\n",
    "                #Purpose : Converts center coordinates to rectangle coordinates\n",
    "\n",
    "                # x, y = midpoint of box\n",
    "\n",
    "                center_x = int(detection[0] * width)\n",
    "\n",
    "                center_y = int(detection[1] * height)\n",
    "\n",
    "                 # w, h = width, height of the box\n",
    "\n",
    "                w = int(detection[2] * width)\n",
    "\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.5)\n",
    "\n",
    "    #print(indexes)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX    \n",
    "\n",
    "    if len(indexes)>0:        \n",
    "\n",
    "        status=list()        \n",
    "\n",
    "        idf = indexes.flatten()        \n",
    "\n",
    "        close_pair = list()        \n",
    "\n",
    "        s_close_pair = list()        \n",
    "\n",
    "        center = list()        \n",
    "\n",
    "        dist = list()        \n",
    "\n",
    "        for i in idf:            \n",
    "\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])            \n",
    "\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])            \n",
    "\n",
    "            center.append([int(x + w / 2), int(y + h / 2)])            \n",
    "\n",
    "            status.append(0)            \n",
    "\n",
    "        for i in range(len(center)):            \n",
    "\n",
    "            for j in range(len(center)):                \n",
    "\n",
    "                #compare the closeness of two values\n",
    "\n",
    "                g=isclose(center[i], center[j])                \n",
    "\n",
    "                if g ==1:                    \n",
    "\n",
    "                    close_pair.append([center[i],center[j]])                    \n",
    "\n",
    "                    status[i] = 1                    \n",
    "\n",
    "                    status[j] = 1                    \n",
    "\n",
    "                elif g == 2:                    \n",
    "\n",
    "                    s_close_pair.append([center[i], center[j]])                    \n",
    "\n",
    "                    if status[i] != 1:                        \n",
    "\n",
    "                        status[i] = 2                        \n",
    "\n",
    "                    if status[j] != 1:                        \n",
    "\n",
    "                        status[j] = 2\n",
    "\n",
    "        total_p = len(center)        \n",
    "\n",
    "        low_risk_p = status.count(2)        \n",
    "\n",
    "        high_risk_p = status.count(1)        \n",
    "\n",
    "        safe_p = status.count(0)        \n",
    "\n",
    "        kk = 0        \n",
    "\n",
    "        for i in idf:            \n",
    "\n",
    "            sub_img = img[10:170, 10:width - 10]            \n",
    "\n",
    "            black_rect = np.ones(sub_img.shape, dtype=np.uint8)*0            \n",
    "\n",
    "            res = cv2.addWeighted(sub_img, 0.77, black_rect,0.23, 1.0)\n",
    "\n",
    "            img[10:170, 10:width - 10] = res           \n",
    "\n",
    "            \n",
    "\n",
    "            # adding text to image            \n",
    "\n",
    "                      #(image,text,org( X coordinate value, Y coordinate value),font,fontScale,color,thikness)\n",
    "\n",
    "            cv2.putText(img, \"Social Distancing Detection - During COVID19 \", (255, 45),font, 1, (255, 255, 255), 2)\n",
    "          \n",
    "\n",
    "            #image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "            cv2.rectangle(img, (20, 60), (625, 160), (170, 170, 170), 2)            \n",
    "\n",
    "            cv2.putText(img, \"Connecting lines shows closeness among people. \", (45, 80),font, 0.6, (255, 255, 0), 1)            \n",
    "\n",
    "            cv2.putText(img, \"YELLOW: CLOSE\", (45, 110),font, 0.5, (0, 255, 255), 1)            \n",
    "\n",
    "            cv2.putText(img, \"RED: VERY CLOSE\", (45, 130),font, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "            cv2.rectangle(img, (675, 60), (width -20, 160), (170, 170, 170), 2)            \n",
    "\n",
    "            cv2.putText(img, \"Bounding box shows the level of risk to the person.\",(685, 80),font, 0.6, (255, 255, 0), 1)           \n",
    "\n",
    "            \n",
    "\n",
    "            cv2.putText(img, \"DARK RED: HIGH RISK\", (685, 110),font, 0.5, (0, 0, 150), 1)      \n",
    "\n",
    "            cv2.putText(img, \"ORANGE: LOW RISK\", (685, 130),font, 0.5, (0, 120, 255), 1)\n",
    "\n",
    "            cv2.putText(img, \"GREEN: CONGRATULATIONS YOU ARE SAFE\", (685, 150),font, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            tot_str = \"NUMBER OF PEOPLE: \" + str(total_p)            \n",
    "\n",
    "            high_str = \"RED ZONE: \" + str(high_risk_p)            \n",
    "\n",
    "            low_str = \"ORANGE ZONE: \" + str(low_risk_p)            \n",
    "\n",
    "            safe_str = \"GREEN ZONE: \" + str(safe_p)            \n",
    "\n",
    "            #image ROI\n",
    "\n",
    "            sub_img = img[height - 120:height-20, 0:500]\n",
    "\n",
    "            #cv2.imshow(\"sub_img\",sub_img)            \n",
    "\n",
    "            black_rect = np.ones(sub_img.shape, dtype=np.uint8) * 0\n",
    "\n",
    "            res = cv2.addWeighted(sub_img, 0.8, black_rect, 0.2, 1.0)\n",
    "\n",
    "            img[height - 120:height-20, 0:500] = res\n",
    "\n",
    "            cv2.putText(img, tot_str, (10, height - 75),font, 0.6, (255, 255, 255), 1)            \n",
    "\n",
    "            cv2.putText(img, safe_str, (300, height - 75),font, 0.6, (0, 255, 0), 1)            \n",
    "\n",
    "            cv2.putText(img, low_str, (10, height - 50),font, 0.6, (0, 120, 255), 1)            \n",
    "\n",
    "            cv2.putText(img, high_str, (300, height - 50),font, 0.6, (0, 0, 150), 1)\n",
    "\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])            \n",
    "\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])        \n",
    "\n",
    "            #color of the ractangle when is too close \n",
    "\n",
    "            if status[kk] == 1:                \n",
    "\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 150), 2)\n",
    "\n",
    "            elif status[kk] == 0:                \n",
    "\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            else:\n",
    "\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 120, 255), 2)\n",
    "\n",
    "            kk += 1\n",
    "\n",
    "        for h in close_pair:            \n",
    "\n",
    "            cv2.line(img, tuple(h[0]), tuple(h[1]), (0, 0, 255), 2)         \n",
    "\n",
    "        for b in s_close_pair:\n",
    "\n",
    "            cv2.line(img, tuple(b[0]), tuple(b[1]), (0, 255, 255), 2)\n",
    "            \n",
    "    cv2.imshow('image',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "        break\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    #FourCC code is passed as\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "    output = cv2.VideoWriter('output4.mp4',fourcc, 20.0, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    #cv2.imwrite(\"output1.mp4\",img)\n",
    "\n",
    "    #img = cv2.flip(img,0)\n",
    "\n",
    "    output.write(img)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "output.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# press 'q' to release the window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
